name: sources
services:
  sources_api:
    working_dir: /api
    build:
      context: ./api
    depends_on:
      sources_rq_redis:
        condition: service_healthy
    command: ["bash", "-c", "poetry run uvicorn api.server:app --host 0.0.0.0 --port 8082 --log-config server_log_config.ini --reload"]
    container_name: sources_api
    ports:
    - mode: ingress
      target: 8082
      published: "8082"
      protocol: tcp
    # restart: always
    environment:
      - ELASTICSEARCH_URL=${ELASTICSEARCH_URL}
      - ES_PORT=${ES_PORT}
    volumes:
    - type: bind
      source: ./api
      target: /api
    networks:
      sources: null
  sources_rq_redis:
    container_name: sources_rq_redis
    # restart: always
    image: redis
    networks:
      sources: null
    ports:
    - mode: ingress
      target: 6379
      published: "6380"
      protocol: tcp
    expose:
      - '6379'
    healthcheck:
      test:
      - CMD
      - redis-cli
      - ping
      timeout: 30s
      interval: 5s
      retries: 50
    # extra_hosts:
    # - host.docker.internal:host-gateway
  sources_workers:
    environment:
      - ELASTICSEARCH_URL=${ELASTICSEARCH_URL}
      - ES_PORT=${ES_PORT}
      - CACHE_DIR_NAME=${CACHE_DIR_NAME}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    working_dir: /workers
    build:
      context: ./workers
    depends_on:
      sources_rq_redis:
        condition: service_healthy
    container_name: sources_workers
    # restart: always
    volumes:
    - type: bind
      source: ./workers
      target: /workers
    networks:
      sources: null
    command: ["bash", "-c", "poetry run rq worker --with-scheduler -c workers.rq_settings"]

    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]
  sources_router:
    image: caddy
    hostname: sources_router.sources
    networks:
      - sources
    container_name: sources_router
    ports:
      - 80:80
    configs:
      - source: sources_router_Caddyfile
        target: /etc/caddy/Caddyfile
    logging:
      driver: json-file
      options:
        max-size: 100m
        max-file: "5"
    profiles:
      - deploy

  # In case we wish to set up separate images for browser
  # sources_chrome:
  #   image: selenium/standalone-chrome:latest
  #   container_name: sources_chrome
  #   # TODO use docker networking to connect
  #   networks:
  #     - sources
  #   hostname: chrome
  #   ports:
  #     - "5900:5900"
  #     - "7900:7900"
  #     - "4444:4444"
  #   privileged: true
  #   shm_size: 2g

  # For Prod with SSL/security, needed to set up nodes
  # setup:
  #   image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
  #   volumes:
  #     - certs:/usr/share/elasticsearch/config/certs
  #   user: "0"
  #   command: >
  #     bash -c '
  #       if [ x${ELASTIC_PASSWORD} == x ]; then
  #         echo "Set the ELASTIC_PASSWORD environment variable in the .env file";
  #         exit 1;
  #       elif [ x${KIBANA_PASSWORD} == x ]; then
  #         echo "Set the KIBANA_PASSWORD environment variable in the .env file";
  #         exit 1;
  #       fi;
  #       if [ ! -f config/certs/ca.zip ]; then
  #         echo "Creating CA";
  #         bin/elasticsearch-certutil ca --silent --pem -out config/certs/ca.zip;
  #         unzip config/certs/ca.zip -d config/certs;
  #       fi;
  #       if [ ! -f config/certs/certs.zip ]; then
  #         echo "Creating certs";
  #         echo -ne \
  #         "instances:\n"\
  #         "  - name: es01\n"\
  #         "    dns:\n"\
  #         "      - es01\n"\
  #         "      - localhost\n"\
  #         "    ip:\n"\
  #         "      - 127.0.0.1\n"\
  #         "  - name: kibana\n"\
  #         "    dns:\n"\
  #         "      - kibana\n"\
  #         "      - localhost\n"\
  #         "    ip:\n"\
  #         "      - 127.0.0.1\n"\
  #         > config/certs/instances.yml;
  #         bin/elasticsearch-certutil cert --silent --pem -out config/certs/certs.zip --in config/certs/instances.yml --ca-cert config/certs/ca/ca.crt --ca-key config/certs/ca/ca.key;
  #         unzip config/certs/certs.zip -d config/certs;
  #       fi;
  #       echo "Setting file permissions"
  #       chown -R root:root config/certs;
  #       find . -type d -exec chmod 750 \{\} \;;
  #       find . -type f -exec chmod 640 \{\} \;;
  #       echo "Waiting for Elasticsearch availability";
  #       until curl -s --cacert config/certs/ca/ca.crt https://es01:9200 | grep -q "missing authentication credentials"; do sleep 30; done;
  #       echo "Setting kibana_system password";
  #       until curl -s -X POST --cacert config/certs/ca/ca.crt -u "elastic:${ELASTIC_PASSWORD}" -H "Content-Type: application/json" https://es01:9200/_security/user/kibana_system/_password -d "{\"password\":\"${KIBANA_PASSWORD}\"}" | grep -q "^{}"; do sleep 10; done;
  #       echo "All done!";
  #     '
  #   healthcheck:
  #     test: ["CMD-SHELL", "[ -f config/certs/es01/es01.crt ]"]
  #     interval: 1s
  #     timeout: 5s
  #     retries: 120     

  sources_es:
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    container_name: sources_es
    networks:
      - sources
    labels:
      co.elastic.logs/module: elasticsearch
    ports:
      - 9200:9200
    environment:
      - http.host=0.0.0.0
      - transport.host=127.0.0.1
      - xpack.security.enabled=false 
      - xpack.security.http.ssl.enabled=false
      - cluster.name=${CLUSTER_NAME}
    mem_limit: ${ES_MEM_LIMIT}
    ulimits:
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      test:
        [
          "CMD",
          "curl http://localhost:9200",
        ]
      timeout: 3s
      interval: 3s
      retries: 20
    volumes:
      - sources_esdata:/usr/share/elasticsearch/data

  # For Prod with https and security, depends on setup
  # es01:
  #   depends_on:
  #     setup:
  #       condition: service_healthy
  #   image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
  #   networks:
  #     - sources
  #   labels:
  #     co.elastic.logs/module: elasticsearch
  #   ports:
  #     - ${ES_PORT}:9200
  #   container_name: es01
  #   environment:
  #     - node.name=es01
  #     - cluster.name=${CLUSTER_NAME}
  #     - discovery.type=single-node
  #     - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
  #     - bootstrap.memory_lock=true
  #     - xpack.security.enabled=true
  #     - xpack.security.http.ssl.enabled=true
  #     - xpack.security.http.ssl.key=certs/es01/es01.key
  #     - xpack.security.http.ssl.certificate=certs/es01/es01.crt
  #     - xpack.security.http.ssl.certificate_authorities=certs/ca/ca.crt
  #     - xpack.security.transport.ssl.enabled=true
  #     - xpack.security.transport.ssl.key=certs/es01/es01.key
  #     - xpack.security.transport.ssl.certificate=certs/es01/es01.crt
  #     - xpack.security.transport.ssl.certificate_authorities=certs/ca/ca.crt
  #     - xpack.security.transport.ssl.verification_mode=certificate
  #     - xpack.license.self_generated.type=${LICENSE}
  #     # - http.host=0.0.0.0
  #     # - transport.host=127.0.0.1
  #     # -e "xpack.security.enabled=false" \
  #     # -e "xpack.security.http.ssl.enabled=false" \
  #   healthcheck:
  #     test:
  #       [
  #         "CMD-SHELL",
  #         "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200 | grep -q 'missing authentication credentials'",
  #       ]
  #     timeout: 3s
  #     interval: 3s
  #     retries: 20
  #   mem_limit: ${ES_MEM_LIMIT}
  #   ulimits:
  #     memlock:
  #       soft: -1
  #       hard: -1
  #   volumes:
  #     - certs:/usr/share/elasticsearch/config/certs
  #     - esdata01:/usr/share/elasticsearch/data

  sources_kibana:
    container_name: sources_kibana
    # depends_on:
    #   sources_es:
    #     condition: service_healthy
    image: docker.elastic.co/kibana/kibana:${STACK_VERSION}
    networks:
      - sources
    labels:
      co.elastic.logs/module: kibana
    volumes:
      # - certs:/usr/share/kibana/config/certs
      - kibanadata:/usr/share/kibana/data
    ports:
      - ${KIBANA_PORT}:5601
    environment:
      - SERVERNAME=kibana
      - ELASTICSEARCH_HOSTS=http://sources_es.sources:9200
      # - ELASTICSEARCH_USERNAME=kibana_system
      # - ELASTICSEARCH_PASSWORD=${KIBANA_PASSWORD}
      # - ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES=config/certs/ca/ca.crt
      # - XPACK_SECURITY_ENCRYPTIONKEY=${ENCRYPTION_KEY}
      # - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=${ENCRYPTION_KEY}
      # - XPACK_REPORTING_ENCRYPTIONKEY=${ENCRYPTION_KEY}
      - xpack.security.enabled=false 
      - xpack.security.http.ssl.enabled=false
    mem_limit: ${KB_MEM_LIMIT}
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s -I http://localhost:5601 | grep -q 'HTTP/1.1 302 Found'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120
  sources_ui:
    image: node:20
    container_name: sources_ui
    volumes:
      - ./ui:/ui
    working_dir: "/ui"
    ports:
      - "3000:3000"
    command: ["npm", "run", "dev"]
    profiles:
      - dev
  sources_rq_dashboard:
    container_name: sources_rq_dashboard
    build: 
      context: ./dev/dockerfiles/rq-dashboard
    ports:
      - '9181:9181'
    networks:
      - sources
    environment:
      RQ_DASHBOARD_REDIS_URL: redis://sources_rq_redis.sources:6379
    command: ["bash", "-c", "rq-dashboard"]
    profiles:
      - dev
configs:
  sources_router_Caddyfile:
    file: Caddyfile
networks:
  sources:
    name: sources
    driver: bridge
volumes:
  # For setting up es in prod
  # certs:
  #   driver: local
  # esdata01:
  #   driver: local
  kibanadata:
    driver: local
  sources_esdata:
    driver: local
