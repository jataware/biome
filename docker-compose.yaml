name: biome
services:
  biome_api:
    working_dir: /backend
    build:
      context: .
      dockerfile: ./backend/docker/Dockerfile.api
    depends_on:
      biome_es:
        condition: service_healthy
      biome_redis:
        condition: service_healthy
    command: > 
      bash -c "poetry run uvicorn api.server:app --host 0.0.0.0 --port 8082 --log-config server_log_config.ini --reload"
    container_name: biome_api
    ports:
    - mode: ingress
      target: 8082
      published: "8082"
      protocol: tcp
    # restart: always
    environment:
      - ES_HOST=${ES_HOST}
      - ES_PORT=${ES_PORT}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_ORG_ID=${OPENAI_ORG_ID}
    volumes:
    - type: bind
      source: ./backend
      target: /backend
    networks:
      - biome
      - biome-beaker
  biome_redis:
    container_name: biome_redis
    # restart: always
    image: redis
    networks:
      - biome
    ports:
    - mode: ingress
      target: 6379
      published: "6380"
      protocol: tcp
    expose:
      - '6379'
    healthcheck:
      test:
      - CMD
      - redis-cli
      - ping
      timeout: 30s
      interval: 5s
      retries: 50
    # extra_hosts:
    # - host.docker.internal:host-gateway
  biome_worker:
    environment:
      - ES_HOST=${ES_HOST}
      - ES_PORT=${ES_PORT}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_ORG_ID=${OPENAI_ORG_ID}
    working_dir: /backend
    build:
      context: .
      dockerfile: ./backend/docker/Dockerfile.worker
    depends_on:
      biome_redis:
        condition: service_healthy
      biome_es:
        condition: service_healthy
    container_name: biome_worker
    # restart: always
    volumes:
    - type: bind
      source: ./backend/
      target: /backend
    - type: bind
      source: ./jvoy-results/
      target: /jvoy/results
    networks:
      - biome
    command: > 
      bash -c  "poetry install 
      && poetry run rq worker --with-scheduler -c worker.rq_configuration"
  biome_router:
    image: caddy
    hostname: biome_router.biome
    networks:
      - biome
    container_name: biome_router
    ports:
      - 8001:8001
    configs:
      - source: biome_router_Caddyfile
        target: /etc/caddy/Caddyfile
    logging:
      driver: json-file
      options:
        max-size: 100m
        max-file: "5"
    profiles:
      - deploy
  biome_es:
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    container_name: biome_es
    networks:
      - biome
    labels:
      co.elastic.logs/module: elasticsearch
    ports:
      - 9200:9200
    environment:
      - http.host=0.0.0.0
      - transport.host=127.0.0.1
      - xpack.security.enabled=false
      - xpack.security.http.ssl.enabled=false
      - cluster.name=${CLUSTER_NAME}
    mem_limit: ${ES_MEM_LIMIT}
    ulimits:
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      test: curl -s -f http://localhost:9200/_cat/health >/dev/null || exit 1
      timeout: 3s
      interval: 5s
      retries: 20
    volumes:
      - esdata:/usr/share/elasticsearch/data

  # For Prod with https and security, depends on setup
  # es01:
  #   depends_on:
  #     setup:
  #       condition: service_healthy
  #   image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
  #   networks:
  #     - biome
  #   labels:
  #     co.elastic.logs/module: elasticsearch
  #   ports:
  #     - ${ES_PORT}:9200
  #   container_name: es01
  #   environment:
  #     - node.name=es01
  #     - cluster.name=${CLUSTER_NAME}
  #     - discovery.type=single-node
  #     - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
  #     - bootstrap.memory_lock=true
  #     - xpack.security.enabled=true
  #     - xpack.security.http.ssl.enabled=true
  #     - xpack.security.http.ssl.key=certs/es01/es01.key
  #     - xpack.security.http.ssl.certificate=certs/es01/es01.crt
  #     - xpack.security.http.ssl.certificate_authorities=certs/ca/ca.crt
  #     - xpack.security.transport.ssl.enabled=true
  #     - xpack.security.transport.ssl.key=certs/es01/es01.key
  #     - xpack.security.transport.ssl.certificate=certs/es01/es01.crt
  #     - xpack.security.transport.ssl.certificate_authorities=certs/ca/ca.crt
  #     - xpack.security.transport.ssl.verification_mode=certificate
  #     - xpack.license.self_generated.type=${LICENSE}
  #     # - http.host=0.0.0.0
  #     # - transport.host=127.0.0.1
  #     # -e "xpack.security.enabled=false" \
  #     # -e "xpack.security.http.ssl.enabled=false" \
  #   healthcheck:
  #     test:
  #       [
  #         "CMD-SHELL",
  #         "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200 | grep -q 'missing authentication credentials'",
  #       ]
  #     timeout: 3s
  #     interval: 3s
  #     retries: 20
  #   mem_limit: ${ES_MEM_LIMIT}
  #   ulimits:
  #     memlock:
  #       soft: -1
  #       hard: -1
  #   volumes:
  #     - certs:/usr/share/elasticsearch/config/certs
  #     - esdata01:/usr/share/elasticsearch/data

  biome_kibana:
    container_name: biome_kibana
    depends_on:
      biome_es:
        condition: service_healthy
    image: docker.elastic.co/kibana/kibana:${STACK_VERSION}
    networks:
      - biome
    labels:
      co.elastic.logs/module: kibana
    volumes:
      # - certs:/usr/share/kibana/config/certs
      - kibanadata:/usr/share/kibana/data
    ports:
      - ${KIBANA_PORT}:5601
    environment:
      - SERVERNAME=kibana
      - ELASTICSEARCH_HOSTS=http://biome_es.biome:9200
      # - ELASTICSEARCH_USERNAME=kibana_system
      # - ELASTICSEARCH_PASSWORD=${KIBANA_PASSWORD}
      # - ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES=config/certs/ca/ca.crt
      # - XPACK_SECURITY_ENCRYPTIONKEY=${ENCRYPTION_KEY}
      # - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=${ENCRYPTION_KEY}
      # - XPACK_REPORTING_ENCRYPTIONKEY=${ENCRYPTION_KEY}
      - xpack.security.enabled=false
      - xpack.security.http.ssl.enabled=false
    mem_limit: ${KB_MEM_LIMIT}
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s -I http://localhost:5601 | grep -q 'HTTP/1.1 302 Found'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120
  biome_ui:
    image: node:20
    container_name: biome_ui
    networks:
      - biome
    volumes:
      - ./ui:/ui
    working_dir: "/ui"
    ports:
      - "3000:3000"
    command: ["npm", "run", "dev"]
    profiles:
      - dev
  biome_rq_dashboard:
    container_name: biome_rq_dashboard
    build:
      context: ./dev/dockerfiles/rq-dashboard
    ports:
      - '9181:9181'
    networks:
      - biome
    environment:
      RQ_DASHBOARD_REDIS_URL: redis://biome_redis.biome:6379
    command: ["bash", "-c", "rq-dashboard"]
    profiles:
      - dev

  # beaker:
  #   build:
  #     context: ./dev/dockerfiles/beaker

  #   ports:
  #     - "8888:8888"
  #   environment:
  #     - JUPYTER_SERVER=http://beaker:8888
  #     - JUPYTER_TOKEN=89f73481102c46c0bc13b2998f9a4fce
  #     - ENABLE_USER_PROMPT=true
  #     - OPENAI_API_KEY
  #     - PYTHONPATH=/jupyter
  #   networks:
  #     - biome
  #   command: ["python", "-m", "beaker_kernel.server.main", "--debug", "--ip", "0.0.0.0"]


  # notebook:
  #   image: node:20
  #   user: node
  #   volumes:
  #     - ./notebook:/ui
  #   working_dir: "/ui"
  #   ports:
  #     - "8080:8080"
  #   command: ["npm", "run", "serve"]
  #   networks:
  #     - biome



configs:
  biome_router_Caddyfile:
    file: Caddyfile
networks:
  biome:
    name: biome
    driver: bridge
  biome-beaker:
    name: biome-beaker
    driver: bridge
volumes:
  # For setting up es in prod
  # certs:
  #   driver: local
  # esdata01:
  #   driver: local
  kibanadata:
    driver: local
  esdata:
    driver: local
